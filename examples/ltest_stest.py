#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# SPDX-License-Identifier: MIT
# Copyright (c) 2025 Jon Paul Lundquist
"""
Created on Mon Sep 29 15:55:15 2025

A rough draft...
Generated by ChatGPT-5 to test accuracy of l_shift and shift_boot values from the
L-test compared to mean and median differences. The results from the tests in this 
file are not necessarily expected to be good: The L-shift is interpretable as a 
location offset only when the L-test fails to reject (i.e., shapes appear compatible). 
Under shape mismatch, it is a nuisance alignment chosen to minimize the ECDF 
distance and should not be interpreted as a population location difference.

From example run:
=== Accuracy summary (skew2_vs_normal) ===
{'delta_dist': 'uniform',
 'delta_sd': 1.0,
 'delta_width': 2.0,
 'families': ('normal', 'skew2'),
 'logsig_sd': 0.35,
 'ltest_B': 500,
 'ltest_tol_p': 0.05,
 'mu_sd': 2.0,
 'n': 200,
 'trials': 800}
{'l_shift': {'Bias': 0.04198671029231616,
             'MAE': 2.0322813545582177,
             'RMSE': 2.329093630471601,
             'SE_Wald_CI_coverage': 0.05,
             'SE_Wald_CI_coverage_CI95': (0.036931386385980994,
                                          0.06736960219912745),
             'SE_Wald_avg_CI_width': np.float64(0.4771742526347662)},
 'mean_diff': {'Bias': -0.00695445051050299,
               'MAE': 0.091369072578875,
               'RMSE': 0.11721823658568811},
 'median_diff': {'Bias': -0.008316472046253048,
                 'MAE': 0.10653856766998324,
                 'RMSE': 0.13634757448014473},
 'shift_boot': {'Bias': 0.04210365332955963,
                'CI_coverage': None,
                'CI_coverage_CI95': None,
                'MAE': 2.033348717189225,
                'RMSE': 2.329863995100157,
                'avg_CI_width': None}}


@author: Jon Paul Lundquist
"""

# ================= Shift Estimator Accuracy vs ltest =================
# Compares l_shift / shift_boot from your ltest() to mean/median diffs.
# Requirements: numpy (SciPy optional for exact binomial CIs).

import math
import numpy as np

# ---- Your L-test (must be importable) ----
# It must return: l_p, l_stat, l_shift, shift_err, shift_boot, cvm_p, t
from ltest import ltest  # <-- ensure this import works in your environment

# ---- Optional: exact Clopper–Pearson CI for coverage, if SciPy is installed ----
try:
    from scipy.stats import beta as _beta_dist
    _HAVE_SCIPY = True
except Exception:
    _HAVE_SCIPY = False


# ------------------- Helpers: coverage CI and parsing -------------------
def prop_ci(successes, n, alpha=0.05, method="wilson"):
    """95% CI for a binomial proportion."""
    if n == 0:
        return (0.0, 1.0)
    p = successes / n
    if method == "clopper" and _HAVE_SCIPY:
        a = alpha / 2.0
        lo = 0.0 if successes == 0 else _beta_dist.ppf(a, successes, n - successes + 1)
        hi = 1.0 if successes == n else _beta_dist.ppf(1 - a, successes + 1, n - successes)
        return (lo, hi)
    # Wilson (no SciPy)
    z = 1.959963984540054
    denom = 1.0 + (z*z)/n
    center = (p + (z*z)/(2*n)) / denom
    half = (z/denom) * math.sqrt(p*(1-p)/n + (z*z)/(4*n*n))
    return (max(0.0, center - half), min(1.0, center + half))


def parse_shift_boot(ret):
    """
    Try to interpret ltest's 'shift_boot' return.
    Accepts:
      - float/int -> treat as point estimate, no CI
      - (est, lo, hi)
      - dict with 'est' and optional 'lo','hi' (order-insensitive)
      - (lo, hi) -> infer est as 0.5*(lo+hi)
      - sequence of boot replicates -> return (median, None, None)
    Returns (est, lo, hi) where lo/hi may be None.
    """
    # scalar
    if isinstance(ret, (float, int)):
        return float(ret), None, None

    # dict
    if isinstance(ret, dict):
        est = float(ret.get("est")) if "est" in ret else None
        lo = ret.get("lo"); hi = ret.get("hi")
        if lo is not None: lo = float(lo)
        if hi is not None: hi = float(hi)
        if est is None and (lo is not None and hi is not None):
            est = 0.5 * (lo + hi)
        if est is None:
            raise TypeError("shift_boot dict lacks 'est' or ('lo','hi').")
        if lo is not None and hi is not None and lo > hi:
            lo, hi = hi, lo
        return est, lo, hi

    # tuple/list
    if isinstance(ret, (tuple, list)):
        L = len(ret)
        if L == 2:
            lo, hi = float(ret[0]), float(ret[1])
            if lo > hi: lo, hi = hi, lo
            return 0.5*(lo+hi), lo, hi
        if L >= 3:
            est, lo, hi = float(ret[0]), float(ret[1]), float(ret[2])
            if lo > hi: lo, hi = hi, lo
            return est, lo, hi
        if L == 1:
            return float(ret[0]), None, None

        # lengthy array-like -> treat as bootstrap replicates
        try:
            arr = np.asarray(ret, dtype=float)
            if arr.ndim == 1 and arr.size >= 10:
                return float(np.median(arr)), None, None
        except Exception:
            pass

    # fallback
    raise TypeError("Unrecognized 'shift_boot' format.")


# ---------------------- Sampling families (parametric) ----------------------
def sample_family(rng, n, family, mu, sigma):
    """
    Draw n samples from a family parameterized by location mu and scale sigma.
    Variance is part of shape; no post-processing.
    """
    if family == "normal":
        return rng.normal(loc=mu, scale=sigma, size=n)

    elif family == "laplace":
        b = sigma / math.sqrt(2.0)  # SD ~ sigma
        return rng.laplace(loc=mu, scale=b, size=n)

    elif family == "t3":
        df = 3.0
        s = sigma * math.sqrt((df - 2.0) / df)
        return mu + s * rng.standard_t(df, size=n)

    elif family == "mix2":
        δ = 1.25
        centers = mu + rng.choice([-1.0, 1.0], size=n) * (δ * sigma)
        return rng.normal(loc=centers, scale=sigma, size=n)

    elif family == "skew2":
        k = 1.8  # right-skew when >1
        p_right = k / (1.0 + k)
        c = math.sqrt(2.0 / (1.0 + k*k))
        σL = sigma * c
        σR = sigma * c * k
        u = rng.random(n)
        left = u >= p_right
        x = np.empty(n)
        x[~left] = rng.normal(loc=mu, scale=σR, size=(~left).sum())
        x[left]  = rng.normal(loc=mu, scale=σL, size=(left).sum())
        return x

    else:
        raise ValueError(f"Unknown family '{family}'")


def draw_pair_with_true_shift(
    rng, n,
    families=("normal", "normal"),  # (fam_x, fam_y)
    mu_sd=2.0,
    logsig_sd=0.35,
    delta_dist="uniform",            # 'uniform' or 'normal'
    delta_width=2.0,                 # if uniform: Δ ~ U[-width, +width]
    delta_sd=1.0                     # if normal:  Δ ~ N(0, delta_sd^2)
):
    """
    One Monte-Carlo trial with known true shift Δ:
      μ_common ~ N(0, mu_sd^2), Δ ~ chosen dist, μ_x = μ_common, μ_y = μ_common + Δ
      σ_x, σ_y ~ LogNormal(0, logsig_sd^2) (median 1)
    Returns (x, y, delta_true).
    """
    mu_common = rng.normal(0.0, mu_sd)
    delta_true = (rng.uniform(-delta_width, delta_width) if delta_dist == "uniform"
                  else rng.normal(0.0, delta_sd))
    mu_x = mu_common
    mu_y = mu_common + delta_true
    sigma_x = math.exp(rng.normal(0.0, logsig_sd))
    sigma_y = math.exp(rng.normal(0.0, logsig_sd))
    fx, fy = families
    x = sample_family(rng, n, fx, mu=mu_x, sigma=sigma_x)
    y = sample_family(rng, n, fy, mu=mu_y, sigma=sigma_y)
    return x, y, delta_true


# ---------------------- Core: evaluate accuracy with ltest ----------------------
def evaluate_shift_accuracy_with_ltest(
    n=200, B=2000, seed=0,
    families=("normal", "normal"),
    mu_sd=2.0, logsig_sd=0.35,
    delta_dist="uniform", delta_width=2.0, delta_sd=1.0,
    ltest_boot_B=500, ltest_tol_p=0.05,
    ci_method="wilson"
):
    """
    Runs B trials. Per trial:
      - Draw (x, y, Δ_true)
      - Call ltest(x, y, B=ltest_boot_B, tol_p=ltest_tol_p)
      - Collect accuracy metrics for: l_shift, shift_boot, mean diff, median diff
    Returns dict with RMSE/MAE/Bias and CI coverage (if available).
    """
    rng = np.random.default_rng(seed)

    acc = {
        "l_shift":     {"sq": 0.0, "abs": 0.0, "bias": 0.0,
                        "se_cov_hits": 0, "se_cov_total": 0, "se_width_sum": 0.0},
        "shift_boot":  {"sq": 0.0, "abs": 0.0, "bias": 0.0,
                        "cov_hits": 0, "cov_total": 0, "ci_width_sum": 0.0},
        "mean_diff":   {"sq": 0.0, "abs": 0.0, "bias": 0.0},
        "median_diff": {"sq": 0.0, "abs": 0.0, "bias": 0.0},
    }

    for _ in range(B):
        x, y, delta_true = draw_pair_with_true_shift(
            rng, n, families=families, mu_sd=mu_sd, logsig_sd=logsig_sd,
            delta_dist=delta_dist, delta_width=delta_width, delta_sd=delta_sd
        )

        # --- Call your L-test ---        
        l_p, l_p_err, l_shift_est, shift_boot_ret, shift_err, l_stat = ltest(
            x, y, B=ltest_boot_B, tol_p=ltest_tol_p
        )

        # l_shift accuracy
        err = float(l_shift_est) - delta_true
        s = acc["l_shift"]
        s["sq"]   += err*err
        s["abs"]  += abs(err)
        s["bias"] += err

        # If shift_err is provided, build a 95% Wald CI for coverage (optional)
        if shift_err is not None:
            try:
                se = float(shift_err)
                lo, hi = l_shift_est - 1.959963984540054*se, l_shift_est + 1.959963984540054*se
                s["se_cov_total"] += 1
                if lo <= delta_true <= hi:
                    s["se_cov_hits"] += 1
                s["se_width_sum"] += (hi - lo)
            except Exception:
                pass  # ignore if shift_err isn't numeric

        # shift_boot accuracy (and coverage if CI present)
        try:
            est_b, lo_b, hi_b = parse_shift_boot(shift_boot_ret)
        except Exception:
            # If parsing fails, fall back to point = l_shift_est
            est_b, lo_b, hi_b = float(l_shift_est), None, None

        errb = est_b - delta_true
        sb = acc["shift_boot"]
        sb["sq"]   += errb*errb
        sb["abs"]  += abs(errb)
        sb["bias"] += errb
        if lo_b is not None and hi_b is not None:
            sb["cov_total"] += 1
            if lo_b <= delta_true <= hi_b:
                sb["cov_hits"] += 1
            sb["ci_width_sum"] += (hi_b - lo_b)

        # mean difference
        md = float(np.mean(y) - np.mean(x))
        errm = md - delta_true
        am = acc["mean_diff"]
        am["sq"]   += errm*errm
        am["abs"]  += abs(errm)
        am["bias"] += errm

        # median difference
        med = float(np.median(y) - np.median(x))
        errd = med - delta_true
        ad = acc["median_diff"]
        ad["sq"]   += errd*errd
        ad["abs"]  += abs(errd)
        ad["bias"] += errd

    # Finalize summary
    def finalize(s):
        out = {
            "RMSE": math.sqrt(s["sq"]/B),
            "MAE":  s["abs"]/B,
            "Bias": s["bias"]/B,
        }
        return out

    results = {k: finalize(v) for k, v in acc.items()}

    # Coverage summaries
    if acc["shift_boot"]["cov_total"] > 0:
        hits = acc["shift_boot"]["cov_hits"]; total = acc["shift_boot"]["cov_total"]
        results["shift_boot"].update({
            "CI_coverage": hits/total,
            "CI_coverage_CI95": prop_ci(hits, total, method=ci_method),
            "avg_CI_width": acc["shift_boot"]["ci_width_sum"]/total
        })
    else:
        results["shift_boot"].update({
            "CI_coverage": None, "CI_coverage_CI95": None, "avg_CI_width": None
        })

    if acc["l_shift"]["se_cov_total"] > 0:
        hits = acc["l_shift"]["se_cov_hits"]; total = acc["l_shift"]["se_cov_total"]
        results["l_shift"].update({
            "SE_Wald_CI_coverage": hits/total,
            "SE_Wald_CI_coverage_CI95": prop_ci(hits, total, method=ci_method),
            "SE_Wald_avg_CI_width": acc["l_shift"]["se_width_sum"]/total
        })
    else:
        results["l_shift"].update({
            "SE_Wald_CI_coverage": None,
            "SE_Wald_CI_coverage_CI95": None,
            "SE_Wald_avg_CI_width": None
        })

    meta = {
        "n": n, "trials": B, "families": families,
        "mu_sd": mu_sd, "logsig_sd": logsig_sd,
        "delta_dist": delta_dist, "delta_width": delta_width, "delta_sd": delta_sd,
        "ltest_B": ltest_boot_B, "ltest_tol_p": ltest_tol_p
    }
    return {"meta": meta, "results": results}


# ------------------------------ Convenience sweeps ------------------------------
FAMILY_PAIRS = {
    "same_normal":  ("normal", "normal"),
    "same_laplace": ("laplace", "laplace"),
    "same_t3":      ("t3", "t3"),
    "same_mix2":    ("mix2", "mix2"),
    "same_skew2":   ("skew2", "skew2"),
    "t3_vs_normal":    ("normal", "t3"),
    "laplace_vs_normal": ("normal", "laplace"),
    "mix2_vs_normal":    ("normal", "mix2"),
    "skew2_vs_normal":   ("normal", "skew2"),
}

def sweep_families_with_ltest(keys=("same_normal","t3_vs_normal","skew2_vs_normal"),
                              n=200, B=2000, seed=0,
                              mu_sd=2.0, logsig_sd=0.35,
                              delta_dist="uniform", delta_width=2.0, delta_sd=1.0,
                              ltest_boot_B=500, ltest_tol_p=0.05, ci_method="wilson"):
    rng = np.random.default_rng(seed)
    out = {}
    for i, k in enumerate(keys):
        fams = FAMILY_PAIRS[k]
        out[k] = evaluate_shift_accuracy_with_ltest(
            n=n, B=B, seed=int(rng.integers(0, 2**31-1)),
            families=fams, mu_sd=mu_sd, logsig_sd=logsig_sd,
            delta_dist=delta_dist, delta_width=delta_width, delta_sd=delta_sd,
            ltest_boot_B=ltest_boot_B, ltest_tol_p=ltest_tol_p,
            ci_method=ci_method
        )
    return out

def sweep_sample_sizes_with_ltest(ns=(50,100,200,400),
                                  family_key="same_normal", B=2000, seed=0,
                                  mu_sd=2.0, logsig_sd=0.35,
                                  delta_dist="uniform", delta_width=2.0, delta_sd=1.0,
                                  ltest_boot_B=500, ltest_tol_p=0.05, ci_method="wilson"):
    fams = FAMILY_PAIRS[family_key]
    out = {}
    for i, n in enumerate(ns):
        out[n] = evaluate_shift_accuracy_with_ltest(
            n=n, B=B, seed=seed+i, families=fams, mu_sd=mu_sd, logsig_sd=logsig_sd,
            delta_dist=delta_dist, delta_width=delta_width, delta_sd=delta_sd,
            ltest_boot_B=ltest_boot_B, ltest_tol_p=ltest_tol_p,
            ci_method=ci_method
        )
    return out


# ------------------------------------ Demo ------------------------------------
if __name__ == "__main__":
    # Example: compare estimators under skewed heavy tails + randomized μ, σ and Δ
    res = evaluate_shift_accuracy_with_ltest(
        n=200, B=800, seed=123,
        families=FAMILY_PAIRS["skew2_vs_normal"],   # shape mismatch + shift
        mu_sd=2.0, logsig_sd=0.35,
        delta_dist="uniform", delta_width=2.0,
        ltest_boot_B=500, ltest_tol_p=0.05
    )
    from pprint import pprint
    print("\n=== Accuracy summary (skew2_vs_normal) ===")
    pprint(res["meta"])
    pprint(res["results"])

    # Optional sweeps:
    # fam_sweep = sweep_families_with_ltest(
    #     keys=("same_normal","t3_vs_normal","skew2_vs_normal"),
    #     n=200, B=600
    # )
    # size_sweep = sweep_sample_sizes_with_ltest(
    #     ns=(50,100,200,400), family_key="same_normal", B=600
    # )
    # pprint(fam_sweep)
    # pprint(size_sweep)
# ================= End: Shift Estimator Accuracy vs ltest =================